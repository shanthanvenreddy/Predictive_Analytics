{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "id": "8YRSZ6kK3Qer",
    "outputId": "cfe3b3f9-fbf9-42bb-b773-af55b532fe20"
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/cse587/spark-2.4.0-bin-hadoop2.7')\n",
    "import pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting numpy\n",
      "  Downloading https://files.pythonhosted.org/packages/03/27/e35e7c6e6a52fab9fcc64fc2b20c6b516eba930bb02b10ace3b38200d3ab/numpy-1.18.4-cp36-cp36m-manylinux1_x86_64.whl (20.2MB)\n",
      "\u001b[K    100% |████████████████████████████████| 20.2MB 60kB/s  eta 0:00:01   13% |████▎                           | 2.7MB 11.7MB/s eta 0:00:02    19% |██████▏                         | 3.9MB 20.7MB/s eta 0:00:01    36% |███████████▉                    | 7.4MB 20.4MB/s eta 0:00:01    49% |███████████████▉                | 10.0MB 10.9MB/s eta 0:00:01    63% |████████████████████▎           | 12.8MB 26.3MB/s eta 0:00:01    73% |███████████████████████▍        | 14.8MB 11.6MB/s eta 0:00:01    82% |██████████████████████████▎     | 16.6MB 15.2MB/s eta 0:00:01    93% |██████████████████████████████  | 19.0MB 39.1MB/s eta 0:00:01\n",
      "\u001b[?25hInstalling collected packages: numpy\n",
      "Successfully installed numpy-1.18.4\n"
     ]
    }
   ],
   "source": [
    "!pip3 install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading https://files.pythonhosted.org/packages/bb/71/8f53bdbcbc67c912b888b40def255767e475402e9df64050019149b1a943/pandas-1.0.3-cp36-cp36m-manylinux1_x86_64.whl (10.0MB)\n",
      "\u001b[K    100% |████████████████████████████████| 10.0MB 165kB/s eta 0:00:01   45% |██████████████▌                 | 4.5MB 11.5MB/s eta 0:00:01    85% |███████████████████████████▍    | 8.6MB 16.4MB/s eta 0:00:01    98% |███████████████████████████████▍| 9.9MB 35.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting python-dateutil>=2.6.1 (from pandas)\n",
      "  Downloading https://files.pythonhosted.org/packages/d4/70/d60450c3dd48ef87586924207ae8907090de0b306af2bce5d134d78615cb/python_dateutil-2.8.1-py2.py3-none-any.whl (227kB)\n",
      "\u001b[K    100% |████████████████████████████████| 235kB 2.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting numpy>=1.13.3 (from pandas)\n",
      "  Using cached https://files.pythonhosted.org/packages/03/27/e35e7c6e6a52fab9fcc64fc2b20c6b516eba930bb02b10ace3b38200d3ab/numpy-1.18.4-cp36-cp36m-manylinux1_x86_64.whl\n",
      "Collecting pytz>=2017.2 (from pandas)\n",
      "  Downloading https://files.pythonhosted.org/packages/4f/a4/879454d49688e2fad93e59d7d4efda580b783c745fd2ec2a3adf87b0808d/pytz-2020.1-py2.py3-none-any.whl (510kB)\n",
      "\u001b[K    100% |████████████████████████████████| 512kB 1.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting six>=1.5 (from python-dateutil>=2.6.1->pandas)\n",
      "  Downloading https://files.pythonhosted.org/packages/65/eb/1f97cb97bfc2390a276969c6fae16075da282f5058082d4cb10c6c5c1dba/six-1.14.0-py2.py3-none-any.whl\n",
      "Installing collected packages: six, python-dateutil, numpy, pytz, pandas\n",
      "Successfully installed numpy-1.18.4 pandas-1.0.3 python-dateutil-2.8.1 pytz-2020.1 six-1.14.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XRWI-KgvwG4l"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " dic487-587.zip  'Part1 (1).ipynb'   test.csv\r\n",
      " mapping.csv\t  sample.csv\t     train.csv\r\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HoHi4QdC5apa"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ast import literal_eval \n",
    "import pyspark.sql.functions as F\n",
    "from pyspark.sql.functions import udf\n",
    "from pyspark.sql.types import StringType, IntegerType, ArrayType\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import StopWordsRemover\n",
    "from pyspark.ml.feature import Tokenizer, RegexTokenizer\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.sql.functions import regexp_replace,col,array_contains,explode\n",
    "from pyspark.sql.functions import split\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from functools import reduce\n",
    "from pyspark.sql.functions import concat_ws\n",
    "from pyspark.ml.classification import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "76Y4Nnuc6OK5"
   },
   "outputs": [],
   "source": [
    "pd_dataFrame = pd.read_csv(r'train.csv')\n",
    "data_spark_dataFrame = spark.createDataFrame(pd_dataFrame)\n",
    "\n",
    "pd_dataFrame['genre']= pd_dataFrame['genre'].apply(literal_eval)\n",
    "all_genre = pd_dataFrame['genre'].to_list()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iXCWVM_pwXz3"
   },
   "outputs": [],
   "source": [
    "labels =['Drama','Comedy','Romance Film','Thriller','Action','World cinema','Crime Fiction','Horror','Black-and-white','Indie','Action/Adventure','Adventure','Family Film','Short Film','Romantic drama','Animation','Musical','Science Fiction','Mystery','Romantic comedy']\n",
    "mat = np.zeros((len(pd_dataFrame),len(labels)))\n",
    "for i,genre in enumerate(all_genre):\n",
    "  for j,g in enumerate(genre):\n",
    "    for k,label in enumerate(labels):\n",
    "        if label==g:\n",
    "          mat[i][k] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a-Zqc1L3zNXZ"
   },
   "outputs": [],
   "source": [
    "labels = \"Drama , Comedy , Romance Film , Thriller , Action , World cinema , Crime Fiction , Horror , Black-and-white , Indie , Action/Adventure , Adventure , Family Film , Short Film , Romantic drama , Animation , Musical , Science Fiction , Mystery , Romantic comedy\"\n",
    "np.savetxt(\"genre_lables.csv\", mat, delimiter=\",\",fmt='%d',header=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4wMajSknMC3W"
   },
   "outputs": [],
   "source": [
    "lables_dataFrame = pd.read_csv(r'genre_lables.csv')\n",
    "test_pd_dataFrame = pd.read_csv(r'test.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RaIkWS1f1hbu"
   },
   "outputs": [],
   "source": [
    "lables_spark_dataFrame = spark.createDataFrame(lables_dataFrame)\n",
    "test_spark_dataFrame = spark.createDataFrame(test_pd_dataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lZUNn84K21fS"
   },
   "outputs": [],
   "source": [
    "ddataFrame1 = data_spark_dataFrame.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "ddataFrame2 = lables_spark_dataFrame.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "ddataFrame3 = test_spark_dataFrame.withColumn(\"row_id\", monotonically_increasing_id())\n",
    "dataFrame = ddataFrame1.join(ddataFrame2, \"row_id\").drop(\"row_id\")\n",
    "test_dataFrame = ddataFrame3.join(ddataFrame2, \"row_id\").drop(\"row_id\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "Z593o_L88AEK",
    "outputId": "6a3870e3-a024-4aef-cee9-190937b2be33"
   },
   "outputs": [],
   "source": [
    "\n",
    "regTokenizer = RegexTokenizer(inputCol=\"plot\", outputCol=\"words\", pattern=\"\\\\W\")\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\")\n",
    "hashingTF = HashingTF(inputCol=\"filtered\", outputCol=\"features\")\n",
    "pipeline = Pipeline(stages=[regTokenizer, remover, hashingTF])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SpJR3QepwhWI"
   },
   "outputs": [],
   "source": [
    "Mdl = pipeline.fit(dataFrame)\n",
    "dataset = Mdl.transform(dataFrame)\n",
    "\n",
    "Mdl2 = pipeline.fit(test_dataFrame)\n",
    "test_dataset = Mdl2.transform(test_dataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bI_skgB9HaAT",
    "outputId": "15a1ec2f-1193-48d1-b223-f5c93cf6de82"
   },
   "outputs": [],
   "source": [
    "\n",
    "dfList = []\n",
    "labelColumns = lables_spark_dataFrame.columns\n",
    "logReg = LogisticRegression(featuresCol = 'features',maxIter=500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Vmdro7rz3LPa"
   },
   "outputs": [],
   "source": [
    "for labelColumn in labelColumns:\n",
    "    logReg.setLabelCol(labelColumn)\n",
    "    logRegModel = logReg.fit(dataset)\n",
    "    pred = logRegModel.transform(test_dataset)\n",
    "    pred = pred.withColumn(\"prediction\",F.col(\"prediction\").cast(IntegerType()))\n",
    "    dfList.append(pred.select(\"movie_id\",\"prediction\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6m2q85P2sqBl",
    "outputId": "348c175c-b462-49f5-a6d3-a4eda9420017"
   },
   "outputs": [],
   "source": [
    "dataFrames_renamed = [dataFrame.selectExpr('movie_id', f'prediction as prediction_{i}') for i, dataFrame in enumerate(dfList)]\n",
    "temp_dataFrame = reduce(lambda x, y: x.join(y, ['movie_id'], how='full'), dataFrames_renamed)\n",
    "col_list = ['prediction_%d' % i for i in range(len(dfList))]\n",
    "temp_dataFrame = temp_dataFrame.withColumn('predictions',concat_ws(\" \",*col_list)).drop(*col_list).toPandas().to_csv(\"predictions_part1.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Part1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
